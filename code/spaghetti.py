# -*- coding: utf-8 -*-
"""spaghetti.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZImdI8XUbXiwOz7qT6hUWf6z9cAl8Sbm
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.python.keras.utils import data_utils
import matplotlib.pyplot as plt
import PIL.Image
from skimage import img_as_float64

''' ~~ I'll make this all more readable if I can get it to work ~~ '''

# TODO: change 224, 244, to image width and height; tf.Variable vs tf.Constant

### VGG 19, max pooling layers replaced with average pooling ###

img_input = layers.Input(shape=(224, 224, 3)) # change this depending on input image dimensions
# Block 1
x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)
x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)
x = layers.AveragePooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)

# Block 2
x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)
x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)
x = layers.AveragePooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)

# Block 3
x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)
x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)
x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)
x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)
x = layers.AveragePooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)

# Block 4
x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)
x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)
x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)
x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)
x = layers.AveragePooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)

# Block 5
x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)
x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)
x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)
x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)
x = layers.AveragePooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)

model = tf.keras.Model(img_input, x)

# Load weights
WEIGHTS_PATH_NO_TOP = ('https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')
weights_path = data_utils.get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP)
model.load_weights(weights_path)

# model.summary()

for layer in model.layers: # necessary?
  layer.trainable = False

##############################

# Pass input content image and output stylized image through network
# for l in range(14): # last layer to be included (conv4_2) is at index 13
#   curr_layer = model.get_layer(index=l)
#   input_content_img = curr_layer(input_content_img)
#   output_stylized_img = curr_layer(output_stylized_img)

content_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')
style_path = tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')

input_content_img = tf.io.read_file(content_path)
input_content_img = np.array(tf.image.decode_image(input_content_img, channels=3), dtype=np.uint8)
input_content_img = PIL.Image.fromarray(input_content_img)
input_content_img = input_content_img.resize((224, 224))
input_content_img = np.array(input_content_img)
input_content_img = img_as_float64(input_content_img)
# plt.imshow(input_content_img)
input_content_img = np.expand_dims(input_content_img, axis=0)


input_style_img = tf.io.read_file(style_path)
input_style_img = np.array(tf.image.decode_image(input_style_img, channels=3), dtype=np.uint8)
input_style_img = PIL.Image.fromarray(input_style_img)
input_style_img = input_style_img.resize((224, 224))
input_style_img = np.array(input_style_img) # currently 0 to 255
input_style_img = img_as_float64(input_style_img)
# plt.imshow(input_style_img)
input_style_img = np.expand_dims(input_style_img, axis=0)

# input_content_img = np.zeros((1, 224, 224, 3))
# input_style_img = np.zeros((1, 224, 224, 3))
output_stylized_img = tf.Variable(np.random.normal(size=(1, 224, 224, 3)))
### CONTENT LOSS ###

content_model = tf.keras.models.Sequential(name='Content Model')
content_model.add(layers.Input(shape=(224, 224, 3)))

for l in range(14):
  curr_layer = model.get_layer(index=l)
  content_model.add(curr_layer)

def get_content_loss():
  return np.square(np.subtract(np.array(content_model(input_content_img), dytpe=np.float32), np.array(content_model(output_stylized_img), dtype=np.float32))).mean()

### STYLE LOSS ###

# Style model 1
style_model_1 = tf.keras.models.Sequential(name='Style Model 1')
style_model_1.add(layers.Input(shape=(224, 224, 3)))
style_model_1.add(model.get_layer(index=1))

# Style model 2
style_model_2 = tf.keras.models.Sequential(name='Style Model 2')
style_model_2.add(layers.Input(shape=(224, 224, 3)))

for l in range(5):
  curr_layer = model.get_layer(index=l)
  style_model_2.add(curr_layer)

# Style model 3
style_model_3 = tf.keras.models.Sequential(name='Style Model 3')
style_model_3.add(layers.Input(shape=(224, 224, 3)))

for l in range(8):
  curr_layer = model.get_layer(index=l)
  style_model_3.add(curr_layer)

# Style model 4
style_model_4 = tf.keras.models.Sequential(name='Style Model 4')
style_model_4.add(layers.Input(shape=(224, 224, 3)))

for l in range(13):
  curr_layer = model.get_layer(index=l)
  style_model_4.add(curr_layer)

# Style model 5
style_model_5 = tf.keras.models.Sequential(name='Style Model 5')
style_model_5.add(layers.Input(shape=(224, 224, 3)))

for l in range(18):
  curr_layer = model.get_layer(index=l)
  style_model_5.add(curr_layer)

######

def get_style_loss():
  # Style 1 Loss # 
  gram_1_in_style = np.dot(np.transpose(np.squeeze(np.array(style_model_1(input_style_img), dtype=np.float32))), np.squeeze(np.array(style_model_1(input_style_img), dtype=np.float32)))
  gram_1_out_stylized = np.dot(np.transpose(np.squeeze(np.array(style_model_1(output_stylized_img), dtype=np.float32))), np.squeeze(np.array(style_model_1(output_stylized_img), dtype=np.float32)))

  style_1_loss = np.square(np.subtract(gram_1_in_style, gram_1_out_stylized)).mean()

  # Style 2 Loss # 
  gram_2_in_style = np.dot(np.transpose(np.squeeze(np.array(style_model_2(input_style_img), dtype=np.float32))), np.squeeze(np.array(style_model_2(input_style_img), dtype=np.float32)))
  gram_2_out_stylized = np.dot(np.transpose(np.squeeze(np.array(style_model_2(output_stylized_img), dtype=np.float32))), np.squeeze(np.array(style_model_2(output_stylized_img), dtype=np.float32)))

  style_2_loss = np.square(np.subtract(gram_2_in_style, gram_2_out_stylized)).mean()

  # Style 3 Loss # 
  gram_3_in_style = np.dot(np.transpose(np.squeeze(np.array(style_model_3(input_style_img), dtype=np.float32))), np.squeeze(np.array(style_model_3(input_style_img), dtype=np.float32)))
  gram_3_out_stylized = np.dot(np.transpose(np.squeeze(np.array(style_model_3(output_stylized_img), dtype=np.float32))), np.squeeze(np.array(style_model_3(output_stylized_img), dtype=np.float32)))

  style_3_loss = np.square(np.subtract(gram_3_in_style, gram_3_out_stylized)).mean()

  # Style 4 Loss # 
  gram_4_in_style = np.dot(np.transpose(np.squeeze(np.array(style_model_4(input_style_img), dtype=np.float32))), np.squeeze(np.array(style_model_4(input_style_img), dtype=np.float32)))
  gram_4_out_stylized = np.dot(np.transpose(np.squeeze(np.array(style_model_4(output_stylized_img), dtype=np.float32))), np.squeeze(np.array(style_model_4(output_stylized_img), dtype=np.float32)))

  style_4_loss = np.square(np.subtract(gram_4_in_style, gram_4_out_stylized)).mean()

  # Style 5 Loss # 
  gram_5_in_style = np.dot(np.transpose(np.squeeze(np.array(style_model_5(input_style_img), dtype=np.float32))), np.squeeze(np.array(style_model_5(input_style_img), dtype=np.float32)))
  gram_5_out_stylized = np.dot(np.transpose(np.squeeze(np.array(style_model_5(output_stylized_img), dtype=np.float32))), np.squeeze(np.array(style_model_5(output_stylized_img), dtype=np.float32)))

  style_5_loss = np.square(np.subtract(gram_5_in_style, gram_5_out_stylized)).mean()
  total_style_loss = style_1_loss + style_2_loss + style_3_loss + style_4_loss + style_5_loss 
  return total_style_loss

def get_total_loss():
  content_loss_weight = 1
  style_loss_weight = 100
  content_loss = get_content_loss()
  style_loss = get_style_loss()

  return content_loss_weight*content_loss + style_loss_weight*style_loss

optimizer = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)

num_epochs = 100
for e in range(num_epochs):
  print("yeet")
  with tf.GradientTape() as tape:
    loss = tf.convert_to_tensor(get_total_loss(), dtype=tf.float32)

  output_stylized_img = tf.convert_to_tensor(output_stylized_img, dtype=tf.float64)
  grad = tape.gradient(loss, output_stylized_img)
  optimizer.apply_gradients([(grad, output_stylized_img)])
  output_stylized_img.assign(tf.clip_by_value(output_stylized_img, clip_value_min=0.0, clip_value_max=1.0))
  output_stylized_img = np.array(output_stylized_img, dtype=np.float64)
  plt.imshow(output_stylized_img)